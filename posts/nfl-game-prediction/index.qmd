---
title: "Predicting NFL Game Outcomes with nflfastR"
author: "Sameer Sapre"
date: "2024-06-30"
categories: [code, analysis] 
image: "nflfastR.png"
execute: 
  warning: false
page-layout: full
  
---

## Intro

Hello everyone! Today I want to share a tutorial on using `nflreadR` to read historic NFL results and model game outcomes with `tidymodels`.

First, a quick introduction of the R packages we'll use. `nflreadR` is a part of the `nflverse` family of packages that easily and efficiently obtain data from NFL games. This includes past games results and statistics. In this post, we'll be using its suite of functions to get the data we need to build a simple predictive model. We'll also use the `tidymodels` package to setup our model and `tidyverse` for data cleaning and manipulation. 

```{r}
# install and load packages
#install.packages("nflreadr")
library('nflreadr')
library("tidyverse")
library('pROC')
library('tidymodels')

```

## Load Data

Now that we have the relevant packages loaded, let's get started getting our data together. Starting with game data, we'll pull game results from 2011 - 2021. Here, we see that we get a schedule where each row (record) represents a game. There's a home and away team, corresponding scores, and more contextual information for each game.

```{r}
# Scrape schedule Results
load_schedules(seasons = seq(2011,2024)) -> nfl_game_results 
head(nfl_game_results)
```


We've loaded our schedules in with some interesting variables to use in our model. However, it's not quite in the format we need it to be. Ideally, we'd like to feed in 2 teams and have the model give us a winner.

```{r}
nfl_game_results %>%
  # Remove the upcoming season
  filter(season < 2024) %>%
  pivot_longer(cols = c(away_team,home_team),
               names_to = "home_away",
               values_to = "team") %>%
  mutate(team_score = ifelse(home_away == "home_team",yes = home_score,no = away_score),
         opp_score = ifelse(home_away == "home_team", away_score,home_score)) %>%  # sort for cumulative avg
  arrange(season,week) %>%
  select(season,game_id,team,team_score,opp_score,week) -> team_games
```

Let's use `pivot_longer()` to rearrange our dataset and select some simple variables before making the matchup set.

## Feature Engineering

Our goal is to be able to predict the outcome of each. To do that, we need to think about what impacts the outcome of a game before teams even take the field. 

In the case of an NFL game it could be things like player skill level, how far a team has to travel, injuries, even the food that players ate the night before. Using `nflreadr` we can see that there are several variables that can potentially impact the game's outcome from injuries to previous results.


We'll start off by pulling in previous_results. By using previous results, we can hopefully capture a team's quality as a predictor for how they will perform in the next game. There are several ways to quantify team strength, some more complex than others, but for this tutorial, we will use cumulative results as a measure of team strength. The results will be in the form of cumulative points scored/allowed and winning percentage leading up to the game.


```{r}
team_games %>%
  arrange(week) %>%
  group_by(season,team) %>%
  # For each team's season calculate the cumulative scores for after each week
  mutate(cumul_score_mean = cummean(team_score),
          cumul_score_opp = cummean(opp_score),
          cumul_wins = cumsum(team_score > opp_score),
          cumul_losses = cumsum(team_score < opp_score),
          cumul_ties = cumsum(team_score == opp_score),
         cumul_win_pct = cumul_wins / (cumul_wins + cumul_losses),
         # Create the lag variable
         cumul_win_pct_lag_1 = lag(cumul_win_pct,1),
         cumul_score_lag_1 = lag(cumul_score_mean,1),
         cumul_opp_lag_1 = lag(cumul_score_opp,1)
         ) %>%
  # Non-lag variables leak info
  select(week,game_id,contains('lag_1')) %>%
  ungroup() -> cumul_avgs
```


Let's also calculate winning percentage as a feature.

```{r ignore = TRUE}
team_games %>%
  group_by(season,team) %>%
  summarise(wins = sum(team_score > opp_score),
            losses = sum(team_score < opp_score),
            ties = sum(team_score == opp_score))%>%
  ungroup() %>%
  arrange(season) %>%
  group_by(team) %>%
  mutate(win_pct = wins / (wins + losses),
         lag1_win_pct = lag(win_pct,1)) %>%
  ungroup() -> team_win_pct
```

This should be a good start, but I still feel like something is missing. Football is a dangerous game and players regularly get injured. Thankfully `nflreadr` provides weekly injury reports. Let's try incorporating that into our model.



```{r}
# Load depth charts and injury reports
dc = load_depth_charts(seq(2011,most_recent_season()))
injuries = load_injuries(seq(2011,most_recent_season()))
```


```{r}
injuries %>%
  filter(report_status == "Out") -> out_inj

dc %>% 
  filter(depth_team == 1) -> starters

# Determine roster position of injured players
starters %>%
  select(-c(last_name,first_name,position,full_name)) %>%
  inner_join(out_inj, by = c('season','club_code' = 'team','gsis_id','game_type','week')) -> injured_starters

# Number of injuries by position
injured_starters %>%
  group_by(season,club_code,week,position) %>%
  summarise(starters_injured = n()) %>%
  ungroup() %>%
  pivot_wider(names_from = position, names_prefix = "injured_",values_from = starters_injured) -> injuries_position

head(injuries_position)

```

Alright, now we have some flags for injured starter at each position. Next, we need to bring all of our new features together.

## Joins

```{r}
nfl_game_results %>%
  inner_join(cumul_avgs, by = c('game_id','season','week','home_team' = 'team')) %>%
  inner_join(cumul_avgs, by = c('game_id','season','week','away_team' = 'team'),suffix = c('_home','_away'))-> w_avgs

# Check for stragglers
nfl_game_results %>%
  anti_join(cumul_avgs, by = c('game_id','season','home_team' = 'team','week')) -> unplayed_games

# Join previous season's results
#w_avgs %>%
#  left_join(team_win_pct,by = c('season','home_team' = 'team')) %>%
#  left_join(team_win_pct, by = c('away_team' = 'team','season'),suffix = c('_home','_away')) -> matchups
```


```{r}

# Indicate whether home team won
w_avgs %>%
  mutate(home_win = as.numeric(result > 0)) -> matchups
```


Now, let's bring in our injury data.

```{r}
matchups %>%
  left_join(injuries_position,by = c('season','home_team'='club_code','week')) %>%
  left_join(injuries_position,by = c('season','away_team'='club_code','week'),suffix = c('_home','_away')) %>%
  mutate(across(starts_with('injured_'), ~replace_na(.x, 0))) -> matchup_full
```



And ... BOOM! We have a dataset with game-by-game matchups and some features to start out. Feel free to peruse the data to find potential features to include in our Model. 


# Building the Model

Before we do any preprocessing, let's split the data.

First, let's remove columns that might leak info to the model. Remember the model must only use information available prior to kickoff.

```{r}
matchup_full %>%
  select(-c(home_score,away_score,overtime,home_team,away_team,away_qb_name,home_qb_name,referee,stadium,home_coach,away_coach,ftn,espn,old_game_id,gsis,nfl_detail_id,pfr,pff,result)) -> matchup_ready
```




```{r}
# Remove columns
matchup_ready = matchup_ready%>%
  # Transform outcome into factor variable
  select(where(is.numeric),game_id) %>% 
  mutate(home_win = as.factor(home_win)) 
```




```{r}
# Split Data
set.seed(123)
matchups24 = matchup_ready %>% filter(season == 2024)
splits = matchup_ready %>% 
  filter(season != 2024) %>%
  initial_split(prop = 0.7)
train_data <- training(splits)
test_data  <- testing(splits)
```


Let's checkout the variables avaialable to us.

```{r}
colnames(train_data)
```

Off the bat we see a lot of variables that we created. Do we really need that many variables tracking injured players? Probably not, but we'll let the model handle this issue later on.

What about NAs? You may have noticed quite a few variables still containing missing values. We can turn to the package `naniar` to investigate the missingness.


```{r}
library(naniar)

gg_miss_var(x = train_data,show_pct = T)

```

It looks like our custom variables have some missingess as well as some wind and temperature variables. There are several ways to deal with this. However, we will use a simple imputation method as provided by `tidymodels`.


```{r}
library('tidymodels')

rec_impute = recipe(formula = home_win ~ .,
                 data = train_data) %>%
  #create ID role (do not remove) game ID. We'll use this to match predictions to specific games
  update_role(game_id, new_role = "ID") %>%
  #for each numeric variable/feature, replace any NA's with the median value of that variable/feature
  step_impute_median(all_numeric_predictors())

# Create recipe to for moneyline model

# Evalate imputation step
tidy(rec_impute, number = 1)

```

Here, we can see what the medians (NA-filler) values for each predictor.

```{r}
imp_models <- rec_impute %>%
  check_missing(all_numeric_predictors()) %>%
  prep(training = train_data)

# Check if imputation worked
imp_models %>%
  bake(train_data) %>%
  is.na() %>%
  colSums()

tidy(imp_models,number = 1)
```



## Modeling 

Ahh finally, now we can get to the actual model building.... which we'll do in about 3 lines of code.

```{r}
library('glmnet')
# Penalized Linear Regression
# Mixture = 1 means pure lasso
lr_mod <- 
  logistic_reg(mixture = 0.05,penalty = 1) %>% 
  set_engine("glmnet")

```

And that's it! We'll start off with a basic logistic regression. There are a few tunable (though we won't be tuning in this post) parameters, but we'll manually set them for this exercise.

Next, we want to train our model with cross-validation, so that we can train and test against different samples to avoid an overfit model as much as we can. 

```{r}
# Create folds for cross-validation
folds <- vfold_cv(train_data)
```

The `tidymodels` workflow helps organize the steps of the model creation and consolidate model objects. We won't go into details of workflows in this post, but there is plenty of online documentation.

```{r}
# create a workflow using recipe and model objects
game_pred_wflow <- 
  workflow() %>% 
  add_model(lr_mod) %>% 
  add_recipe(rec_impute)

```




```{r}

fit_cv = game_pred_wflow %>%
  fit_resamples(folds)

```

Check for best model fit. It looks like using ROC-AUC and accuracy agree that the first model is the best.


```{r}
collect_metrics(fit_cv)
```


Extract best model fit.


```{r}
final_wf = game_pred_wflow %>%
  last_fit(splits)
```


```{r}
final_model = extract_workflow(final_wf)
```


Get variable estimates and penalty terms.

```{r}
final_model %>%
  extract_fit_engine() %>%
  tidy() %>%
  rename(penalty = lambda)
```




```{r}

# Align predictions to test dataset
predicted_df = augment(final_model,test_data) 
```

Now, so we get a sample boost, let's retrain the model on the full training sample.

```{r hide = T}

# Extract model specs
final_model %>%
  extract_spec_parsnip() -> final_specs

# Update workflow object and retrain on full training set w/ same parameters
game_pred_wflow %>%
  update_model(spec = final_specs) %>%
  # Bind test and training data together
  fit(data = cbind(train_data,test_data))-> final_flow

```



Let's now save the model for future use and investigation.

```{r}

library(yaml)

final_flow %>%
  extract_fit_parsnip() %>%
  saveRDS(file = "gamePred_model2024.rda")

```



We'll use this model to make predictions on future games and evaluate how our model performs in real-time.



